{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use the PigeonSuperModel DataSet\n",
    "\n",
    "Download this notebook in the upper right corner as `.ipynb` file and start it from within your DeepLabCut environment. If you need to install DeepLabCut first, please check [here](https://pigeonsupermodel.com/DLC_StudentGuide.html#installation). \n",
    "\n",
    "This notebook will show you how to create a pretrained project with the PigeonSuperModel and how to download and merge the pre-labeled PigeonSuperModel dataset to increase your own training data:\n",
    "\n",
    "- Create a new PigeonSuperModel Project\n",
    "- Extract new Frames\n",
    "- Label your own Data\n",
    "- Merge PigeonSuperModel DataSet\n",
    "- Re-Train the PigeonSuperModel\n",
    "- Evaluate your new PigeonSuperModel\n",
    "- Contribute to PigeonSuperModel.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import deeplabcut\n",
    "from tkinter import filedialog\n",
    "\n",
    "print(f'Using DeepLabCut version: {deeplabcut.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new project\n",
    "\n",
    "See Notebook before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = r'F:\\PigeonSuperModel_local\\ForAnalysisVideoData\\StopSignal'\n",
    "video_list = os.listdir(video_path)\n",
    "projectpath = r'F:\\PigeonSuperModel_local\\DeepLabCutModels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monkeypatch():\n",
    "    '''\n",
    "    This function locates a file named 'pose_estimation_tensorflow/models/pretrained/pretrained_model_urls.yaml' in your local DeepLabCut\n",
    "    installation and adds the new URLs below to reach the PigeonSUperModel repository.\n",
    "    In a last step, the names of the PigeonSuperModels are added to the 'modelzoo.py' Modeloptions as valid model names.\n",
    "    '''\n",
    "    from deeplabcut.create_project import modelzoo\n",
    "\n",
    "    # locate the `pretrained_model_urls.yaml` file in your local DeepLabCut installation (hardcoded based on deeplabcut dir structure)\n",
    "    neturls_path = os.path.join(deeplabcut.auxiliaryfunctions.get_deeplabcut_path(), 'pose_estimation_tensorflow', 'models', 'pretrained', 'pretrained_model_urls.yaml')\n",
    "\n",
    "    edits = {'PigeonSuperModel_resnet_50':  'https://gitlab.ruhr-uni-bochum.de/ikn/pigeonsupermodel/-/raw/main/models/DeepLabCut/DLC_PigeonSuperModel_01_resnet_50_iteration-2_shuffle-3.tar.gz',\n",
    "             'PigeonSuperModel_resnet_101': 'https://gitlab.ruhr-uni-bochum.de/ikn/pigeonsupermodel/-/raw/main/models/DeepLabCut/DLC_PigeonSuperModel_01_resnet_101_iteration-2_shuffle-4.tar.gz', \n",
    "             'PigeonSuperModel_resnet_152': 'https://gitlab.ruhr-uni-bochum.de/ikn/pigeonsupermodel/-/raw/main/models/DeepLabCut/DLC_PigeonSuperModel_01_resnet_152_iteration-2_shuffle-5.tar.gz'}\n",
    "    \n",
    "    # add new model to the neturls file     \n",
    "    deeplabcut.auxiliaryfunctions.edit_config(neturls_path, edits)\n",
    "\n",
    "    # add new model to locally loaded Modeloptions from modelzoo.py\n",
    "    modelzoo.Modeloptions.extend(['PigeonSuperModel_resnet_50', 'PigeonSuperModel_resnet_101', 'PigeonSuperModel_resnet_152'])\n",
    "    \n",
    "# you may need admin rights on your computer to edit the files above\n",
    "monkeypatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummy_videos(target_dir):\n",
    "    import urllib.request\n",
    "    import cv2\n",
    "\n",
    "    # create dummy video\n",
    "    logolink = 'https://gitlab.ruhr-uni-bochum.de/ikn/pigeonsupermodel/-/raw/main/PigeonSuperModel.png?inline=false'\n",
    "    logo = os.path.join(target_dir, 'logo.png')\n",
    "    urllib.request.urlretrieve(logolink, logo);\n",
    "\n",
    "    dummyvideo = os.path.join(target_dir, 'logo.mp4')\n",
    "    img_array = []\n",
    "    for i in range(20):\n",
    "        img = cv2.imread(logo)\n",
    "        height, width, layers = img.shape\n",
    "        img_array.append(img)\n",
    "    \n",
    "    os.remove(logo)\n",
    "    \n",
    "    out = cv2.VideoWriter(dummyvideo, cv2.VideoWriter_fourcc(*'mp4v'), 20, (width, height))\n",
    "    for i in range(len(img_array)):\n",
    "        out.write(img_array[i])\n",
    "    out.release()\n",
    "\n",
    "    return dummyvideo\n",
    "\n",
    "# create dummy video to use copy=True\n",
    "video_path = create_dummy_videos(projectpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pre-trained model from PigeonSuperModel\n",
    "config_path, _ = deeplabcut.create_pretrained_project(\n",
    "    'StopSignal',\n",
    "    'PigeonSuperModel',\n",
    "    [video_path],\n",
    "    videotype='mp4',\n",
    "    copy_videos=True,\n",
    "    working_directory=projectpath,\n",
    "    model='PigeonSuperModel_resnet_50',\n",
    "    analyzevideo=False,\n",
    "    filtered=False,\n",
    "    createlabeledvideo=False,\n",
    "    )\n",
    "    \n",
    "os.remove(video_path)\n",
    "sign = {'PigeonSuperModel': f'The pretrained PigeonSuperModel was added to this project. (C) PigeonSuperModel.com'}\n",
    "deeplabcut.auxiliaryfunctions.edit_config(config_path, sign)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copying the videos may take very long, and creating hyperlinks does not always work on windows. Alternatively, \n",
    "we can add the video paths to the `config.yaml` file while leaving our video data on a separate disk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patch: add video links to config.yaml\n",
    "def add_videopaths(config, video_list):\n",
    "    from pathlib import Path\n",
    "    from deeplabcut.utils.auxfun_videos import VideoReader\n",
    "\n",
    "    videos = video_list\n",
    "    original_video_sets = deeplabcut.auxiliaryfunctions.read_config(config)['video_sets']\n",
    "    projectpath = deeplabcut.auxiliaryfunctions.read_config(config)['project_path']\n",
    "    \n",
    "    # create new dict for video_sets\n",
    "    video_sets = {}\n",
    "    for video in videos:\n",
    "        print(f'Adding video: {video}')\n",
    "        try:\n",
    "            rel_video_path = str(Path.resolve(Path(video)))\n",
    "            vid = VideoReader(rel_video_path)\n",
    "            video_sets[rel_video_path] = {\"crop\": \", \".join(map(str, vid.get_bbox()))}\n",
    "        except:\n",
    "            print(f'Could not read video, writing fake frame dimensions ...')\n",
    "            rel_video_path = str(Path.resolve(Path(video)))\n",
    "            video_sets[rel_video_path] = {\"crop\": \", \".join(map(str, [0, 1920, 0, 1080]))} # how bad is this\n",
    "        \n",
    "        # create labels directory\n",
    "        labeldir = os.path.basename(video).split('.')[0]\n",
    "        \n",
    "        if os.path.isdir(os.path.join(projectpath,'labeled-data', labeldir)):\n",
    "            print('Labels directory already exists!')\n",
    "        else:\n",
    "            print(f'Creating directoy: {labeldir}')\n",
    "            os.mkdir(os.path.join(projectpath,'labeled-data', labeldir))\n",
    "\n",
    "    # expand existing video_sets\n",
    "    if original_video_sets is None:\n",
    "        new_video_sets = video_sets\n",
    "    else:\n",
    "        new_video_sets = {**original_video_sets, **video_sets}\n",
    "\n",
    "    # add videos to project\n",
    "    edit = {'video_sets': new_video_sets}\n",
    "    deeplabcut.auxiliaryfunctions.edit_config(config, edit);\n",
    "\n",
    "    return\n",
    "\n",
    "# add video paths\n",
    "#video_list = filedialog.askopenfilenames(title = 'Choose video paths to include to your project')\n",
    "add_videopaths(config_path, video_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively you can just load a previously created model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load new project (see Notebook before to create a new project)\n",
    "config = filedialog.askopenfilenames(title='Choose the config.yaml file of your DeepLabCut project:')\n",
    "config_path = config[0]\n",
    "\n",
    "print(f'Using project path: {config_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Optional: Create 3D project to match synchronous frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 3d config\n",
    "config_3d = deeplabcut.create_new_project_3d('StopSignal','3D',num_cameras = 2, working_directory=deeplabcut.auxiliaryfunctions.read_config(config_path)['project_path'])\n",
    "\n",
    "# change settings\n",
    "edits = {'camera_names': ['camR', 'camL']}\n",
    "deeplabcut.auxiliaryfunctions.edit_config(config_3d, edits);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_3d = r'F:\\PigeonSuperModel_local\\DeepLabCutModels\\StopSignal-PigeonSuperModel-2022-07-08\\StopSignal-3D-2022-07-08-3d\\config.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract New Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select videos for primary camera\n",
    "video_sets = deeplabcut.auxiliaryfunctions.read_config(config_path)['video_sets']\n",
    "primary_camera = deeplabcut.auxiliaryfunctions.read_config(config_3d)['camera_names'][0]\n",
    "videos_primary = [str(video) for video in video_sets if primary_camera in video]\n",
    "\n",
    "# change the number of frames to extract\n",
    "edits = {'numframes2pick': 10}\n",
    "\n",
    "# write changes to config.yaml\n",
    "deeplabcut.auxiliaryfunctions.edit_config(config_path, edits);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract frames\n",
    "# Note: videos_list parameter is only available since dlc==2.2.1\n",
    "deeplabcut.extract_frames(config_path, mode=\"automatic\", algo=\"uniform\", userfeedback = False, videos_list = videos_primary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Extract Matching Frames in 3D projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_mp4toavi(config):\n",
    "    import cv2\n",
    "    import shutil\n",
    "\n",
    "    # get videos from config.yaml\n",
    "    video_sets = deeplabcut.auxiliaryfunctions.read_config(config)['video_sets'].keys()\n",
    "    projectpath = deeplabcut.auxiliaryfunctions.read_config(config)['project_path']\n",
    "    original_videos = [video for video in video_sets]\n",
    "    # patch videos for matched frame extraction se here: https://github.com/DeepLabCut/DeepLabCut/issues/1211#issuecomment-1177537516\n",
    "    patched_videos = [os.path.join(projectpath, 'videos', os.path.basename(video).split('.')[0] + '.avi') for video in original_videos]\n",
    "    # change video extension and move\n",
    "    for old, new in zip(original_videos, patched_videos):\n",
    "        # test and close videos\n",
    "        cap = cv2.VideoCapture(video)\n",
    "        while(cap.isOpened()):\n",
    "            # read first frame\n",
    "            cap.read()       \n",
    "            # break after first frame\n",
    "            break\n",
    "        cap.release()\n",
    "        # Closes all the frames\n",
    "        cv2.destroyAllWindows() \n",
    "        # rename\n",
    "        if os.path.isfile(new):\n",
    "            print(f'File {new} already exists')\n",
    "        else:\n",
    "            shutil.move(old, new)\n",
    "            #os.rename(old, new)\n",
    "            print(f'Video: {old} changed to {new}')\n",
    "    \n",
    "    return original_videos, patched_videos\n",
    "    \n",
    "def patch_reverse_mp4toavi(original_videos, patched_videos):\n",
    "    import shutil\n",
    "    for old, new in zip(original_videos, patched_videos):\n",
    "        # reverse video patch to original\n",
    "        shutil.move(new, old)\n",
    "        print(f'Video: {new} reversed to {old}')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patch videos for matched frames see here: https://github.com/DeepLabCut/DeepLabCut/issues/1211#issuecomment-1177537516\n",
    "original_videos, patched_videos = patch_mp4toavi(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overwrite matched synchronous frames with mode=\"match\" and config3d file\n",
    "deeplabcut.extract_frames(config_path, mode=\"match\", config3d=config_3d, extracted_cam=0, userfeedback = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse patched videos\n",
    "patch_reverse_mp4toavi(original_videos, patched_videos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label your own Data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually label frames\n",
    "deeplabcut.label_frames(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check labels\n",
    "deeplabcut.check_labels(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the PigeonSuperModel DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to use the PigeonSuperModel Dataset. Once you have your own DeepLabCut project for single Pigeon tracking, why not spiking your dataset with an extra 1000 pre-labeled frames? The cells below will guide you through this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a single function\n",
    "def merge_psm_dataset(config):\n",
    "\n",
    "    import urllib.request\n",
    "    import tarfile\n",
    "    import pandas as pd\n",
    "    from pathlib import Path\n",
    "    \n",
    "    # read config.yaml\n",
    "    target_dir = deeplabcut.auxiliaryfunctions.read_config(config)['project_path']\n",
    "    scorer = deeplabcut.auxiliaryfunctions.read_config(config)['scorer']\n",
    "    original_video_sets = deeplabcut.auxiliaryfunctions.read_config(config)['video_sets']\n",
    "\n",
    "    # download\n",
    "    print('Downloading DataSet from: gitlab.ruhr-uni-bochum.de/ikn/pigeonsupermodel ...')\n",
    "    dataset_url = 'https://gitlab.ruhr-uni-bochum.de/ikn/pigeonsupermodel/-/archive/main/pigeonsupermodel-main.tar.gz?path=dataset/DeepLabCut/labeled-data'\n",
    "    filename, _ = urllib.request.urlretrieve(dataset_url)\n",
    "    statement = 'The PigeonSuperModel Dataset was added to this project to increase the number of labeled frames. (C) PigeonSuperModel.com'\n",
    "    # Extract .tar\n",
    "    print(f'Extracting tar file to: {target_dir} ...')\n",
    "    with tarfile.open(filename, mode=\"r:gz\") as tar:\n",
    "        tar.extractall(target_dir)\n",
    "\n",
    "    dataset_path = [os.path.join(target_dir, path) for path in os.listdir(target_dir) if 'pigeonsupermodel' in path][0]\n",
    "\n",
    "    # scrap pre-labeled dataset\n",
    "    print(f'Merging Dataset to: {os.path.join(target_dir, \"labeled-data\")} ...')\n",
    "    for root, dirs, files in os.walk(dataset_path):\n",
    "        for f in files:\n",
    "            if '.h5' in f:\n",
    "                h5file = os.path.join(root, f)\n",
    "                # rename scorer in .h5\n",
    "                df = pd.read_hdf(h5file)\n",
    "                df.columns = df.columns.set_levels([scorer], level=0)\n",
    "                \n",
    "                # rename .h5 file\n",
    "                rename = os.path.join(root, f'CollectedData_{scorer}.h5')\n",
    "                df.to_hdf(rename, key = \"df_with_missing\", mode=\"w\")\n",
    "\n",
    "                # move frame set to labeled-data\n",
    "                src = root\n",
    "                dst = os.path.join(target_dir, 'labeled-data', os.path.basename(root))\n",
    "                os.rename(src, dst)\n",
    "\n",
    "    # add dummy videopaths to config.yaml files\n",
    "    print('Adding video paths to \"video_sets\" in config.yaml ...')\n",
    "    framesets = os.listdir(os.path.join(target_dir, 'labeled-data'))\n",
    "    videos = [os.path.join(target_dir, 'videos',frameset+'.avi') for frameset in framesets]\n",
    "\n",
    "    # create new dict for video_sets\n",
    "    video_sets = {}\n",
    "    for video in videos:\n",
    "        rel_video_path = str(Path.resolve(Path(video)))\n",
    "        video_sets[rel_video_path] = {\"crop\": \", \".join(map(str, [0, 1920, 0, 1080]))} # how bad is this?\n",
    "            \n",
    "    # expand existing video_sets\n",
    "    if original_video_sets is None:\n",
    "        new_video_sets = video_sets\n",
    "    else:\n",
    "        new_video_sets = {**original_video_sets, **video_sets}\n",
    "\n",
    "    # add video paths to project\n",
    "    edit = {'video_sets': new_video_sets, \n",
    "            'PigeonSuperModel_data': statement}\n",
    "    deeplabcut.auxiliaryfunctions.edit_config(config, edit);\n",
    "\n",
    "    print('The PigeonSuperModel Dataset has been successfully merged to your project! Enjoy')\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_psm_dataset(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are ready to create a training dataset and train your own model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-Train the PigeonSuperModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training set\n",
    "deeplabcut.create_training_dataset(config_path, num_shuffles=1, net_type='resnet_50', augmenter_type='imgaug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find pose_cfg.yaml\n",
    "for root, dirs, files in os.walk(deeplabcut.auxiliaryfunctions.read_config(config)['project_path']):\n",
    "    for file in files:\n",
    "        if 'pose_cfg.yaml' in file:\n",
    "            pose_cfg = os.path.join(root, file)\n",
    "pose_cfg\n",
    "\n",
    "# edit relevant training parameters\n",
    "edits = {'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], # change this to train over 1M iterations\n",
    "        'init_weights': path_to_lastsnapshot, # change this to use pre-trained model\n",
    "        'max_input_size': 2000, # change this to largest frame dimension in dataset\n",
    "        'global_scale': 0.4, # change this to rescale frames to reduce GPU load\n",
    "        }\n",
    "deeplabcut.auxiliaryfunctions.edit_config(pose_cfg, edits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "deeplabcut.train_network(config_path, max_snapshots_to_keep=None, displayiters=1000, saveiters=10000, maxiters=1000000, allow_growth=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate your new PigeonSuperModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change config.yaml file to evaluate all snapshots\n",
    "edits = {'snapshotindex': 'all'}\n",
    "deeplabcut.auxiliaryfunctions.edit_config(config_path, edits)\n",
    "\n",
    "# evaluate snapshots\n",
    "deeplabcut.evaluate_network(config_path, plotting=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_evaluation_results(config):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # read config\n",
    "    config = deeplabcut.auxiliaryfunctions.read_config(config)\n",
    "    projectpath = config['project_path']\n",
    "    iteration = config['iteration']\n",
    "    modelname = config['Task']\n",
    "    pcutoff = config['pcutoff']\n",
    "    videores = list(config['video_sets'].items())[0][1]['crop'].split(',')[1:4:2]\n",
    "    \n",
    "    # read evaluation results\n",
    "    evals = os.path.join(projectpath, 'evaluation-results', f'iteration-{iteration}', 'CombinedEvaluation-results.csv')\n",
    "    df = pd.read_csv(evals)\n",
    "    evaluation_results = df.loc[:, ~df.columns.isin(['Unnamed: 0', '%Training dataset', 'Shuffle number', 'p-cutoff used'])]\n",
    "    evaluation_results\n",
    "\n",
    "    # plot evaluation results\n",
    "    evaluation_results.plot.line(x = 'Training iterations:', \n",
    "                title = f\"Evaluation results of DLC Model {modelname}\", \n",
    "                ylabel = f\"Pixel Error in {videores[0]}:{videores[1]} resolution frames\",\n",
    "                xlabel = f\"Training Iterations in DLC [p-cutoff = {pcutoff}]\",\n",
    "                xticks = np.arange(0, 1000001, 40000),\n",
    "                rot = 45, figsize = (15,10))\n",
    "    plt.ticklabel_format(axis='both', style='plain')\n",
    "    plt.show()\n",
    "\n",
    "    # check evaluation results\n",
    "    return evaluation_results\n",
    "\n",
    "# show evaluation results\n",
    "check_evaluation_results(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export model\n",
    "deeplabcut.export_model(config_path, shuffle=0, iteration=0, snapshotindex=-1, make_tar=True, modelprefix='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contribute to PigeonSuperModel.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you have an improved version of the PigeonSuperModel?\n",
    "\n",
    "Share your labeled data and your new trained model with us to contribute to the PigeonSuperModel.com. \n",
    "\n",
    "Get in touch at Guillermo.HidalgoGadea@ruhr-uni-bochum.de or at GuillermoHidalgoGadea.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('dlc221')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c5bbe32f0b21b19ff06284fa84621b1e20dc5a7f1cf2439dfc945f2e86a2d9ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}